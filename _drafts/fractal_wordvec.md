Fractal Structure in Word2vec Word Embeddings

I like fractals. After long experience with them, I have come to the point where I do not like to see them. I am completely indifferent to their beauty and their geometric form, although of course they are beautiful. I like them for their [statistical omnipresence](http://arxiv.org/abs/cond-mat/0412004), as most statisticians like the Gaussian.

I like to imagine sometimes that the Gaussian and related distributions are to systems whose variables are independent, as the fractal distributions - the Zipf-Mandelbrot distributions and the like - are to systems whose variables are dependent. This is not an evidenced thought, but I like to imagine it.

Outside of fantasy, we can state a more specific fact about a more specific system whose variables are obviously dependent. I will claim that the global structure of the set of points created by word2vec in a high-dimensional vector space is an approximate fractal, and buttress this claim with evidence. I will have one chart and _no other pictures_.

It is exceedingly easy to intuitively define what a fractal is if you are allowed to use pictures and exceedingly hard if you are not allowed to use pictures. I will use one possible definition of many: having a correlation dimension less than the geometric dimension. [Wikipedia explains](https://en.wikipedia.org/wiki/Correlation_dimension) correlation dimension much better than I can.

Upon inspection, you may note that this procedure is subject to the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality). To ameliorate that curse, I take a comparatively low-dimensionality word2vec: only 10 dimensions. The other existing measures of dimension used for this kinds of analysis ([Minkowski-Bouligand dimension](http://mathworld.wolfram.com/InformationDimension.html) and [information dimension](http://mathworld.wolfram.com/InformationDimension.html)) get it worse, though.

Correlation dimension has more numerical problems than the Wikipedia article notes for it, especially in low dimension: usually for a circle or other non-fractal 2d polygon it will have a dimension value of about 1.9. But it will, for example, get the dimension for Sierpinski triangles right, at about 1.54 (the analytical Hausdorff-Besicovich dimension is known for them, at log(3) / log(2), or about 1.58). So only pay attention if the correlation dimension is __much__ less than what you would expect the dimension to be.

The algorithm to get correlation dimension is also O(n^2) with n being the number of points, so I take a 10,000 point sample of the vectors only.

The corpus is the [Brown corpus](http://www.nltk.org/book/ch02.html#brown-corpus), from newspapers. The word2vec implementation is the [Python wrapper](https://github.com/danielfrg/word2vec) around the original implementation. The code for the analysis of the vectors is [here](https://github.com/howonlee/wordvec_fractal). And now, the chart.




I won't give any explanations for the phenomenon. But I suspect that it is related to Zipf's law, but in a more circuitous way than the easy explanation of the fact that Zipf's law holds for nearly all linguistic representation and word2vec is simply another linguistic representation. Perhaps chaos is involved, given that this phenomenon could be construed as a sort of view of a strange attractor. I note that many dynamical analyses of neural network phenomena leave out chaotic analyses, like [Pascanu Mikolov Bengio 2013](http://www.jmlr.org/proceedings/papers/v28/pascanu13.pdf) (although Pascanu Mikolov Bengio 2013 is for recursive neural networks). But if these systems have strange attractors, the possibility of chaos __must__ be investigated.

I would hypothesize that this is not an extraordinarily particular phenomenon about neural representations, limited to word2vec. Fractal structures and power-law distributions seem to be surprisingly common in neural networks. Try training a simple backpropagation multilayer perceptron on MNIST and then [take the histograms](https://github.com/howonlee/mlp_gradient_histograms) of the absolute values of the weights - you will get a very heavy tail on that histogram. I am currently implementing the [Clauset Shalizi Newman 2007](http://arxiv.org/abs/0706.1062) steps to find if it's a proper power law.
 
I wish to also state a related contention. In the year 2016, if someone is told to model a random landscape, an imaginary landscape generated by computer, they would be remiss if they did not think about fractals. If someone is told to succinctly model real landscapes in order to compress them, they would be remiss if they did not think a little about fractals. I believe that in modelling a different kind of imaginary landscape - the energy landscapes that gradient descent algorithms rattle about in - we should investigate whether it is also remiss in this case to not think a little about fractals.
