Fractal Structure in Word2vec Word Embeddings

I like fractals. After long experience with them, I have come to the point where I do not like to see them. I am completely indifferent to their beauty and their geometric form. I like them for their statistical omnipresence, as most statisticians like the Gaussian.

I like to imagine sometimes that the Gaussian and related distributions are to systems whose variables are independent, as the fractal distributions - the Zipf-Mandelbrot distributions and the like - are to systems whose variables are dependent. This is not an evidenced thought.

Outside of fantasy, we can state a more specific fact about a more specific system whose variable are obviously dependent. I will claim that the global structure of the set of points created by word2vec in a high-dimensional vector space is a fractal, and buttress this claim with evidence. I will have one chart and _no other pictures_.

It is exceedingly easy to intuitively define what a fractal is if you are allowed to use pictures and exceedingly hard if you are not allowed to use pictures. I will use one possible definition of many: having a noninteger [correlation dimension](https://en.wikipedia.org/wiki/Correlation_dimension). Wikipedia explains correlation dimension much better than I can. Upon inspection, you may note that this procedure is subject to the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality). To ameliorate it, I take a comparatively low-dimensionality word2vec: only 10 dimensions.

The corpus is the [Brown corpus](http://www.nltk.org/book/ch02.html#brown-corpus), from newspapers. The word2vec implementation is the [Python wrapper](https://github.com/danielfrg/word2vec) around the original implementation. The code for the analysis of the vectors is [here](https://github.com/howonlee/wordvec_fractal).




I won't give any explanations for the phenomenon. But I suspect that it is related to Zipf's law, but in a more circuitous way than the easy explanation. Perhaps chaos is involved, given that this phenomenon could be construed as a view of a strange attractor. I note that many dynamical analyses of neural network phenomena leave out chaotic analyses, like [Pascanu et al 2013](http://www.jmlr.org/proceedings/papers/v28/pascanu13.pdf).

I would hypothesize that this is not an extraordinarily particular phenomenon about neural representations, limited to word2vec. Fractal structures and power-law distributions seem to be surprisingly common in neural networks. Try training a backpropagation multilayer perceptron on MNIST and then [take the histograms](https://github.com/howonlee/mlp_gradient_histograms) of the absolute values of the weights - you will get a very heavy tail on that histogram. I am currently implementing the [Clauset Shalizi Newman 2007](http://arxiv.org/abs/0706.1062) steps to find if it's a proper power law.
 
In the year 2016, if someone is told to model a random landscape, an imaginary landscape generated by computer, they would be remiss if they did not think about fractals. If someone is told to succinctly model real landscapes in order to compress them, they would be remiss if they did not think a little about fractals. I believe that in modelling a different kind of imaginary landscape - the energy landscapes that gradient descent algorithms rattle about in - we should investigate whether it is also remiss in this case to not think a little about fractals.
