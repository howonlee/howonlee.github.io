Fractal Structure in Word2vec Word Embeddings

I like fractals. After long experience with them, I have come to the point where I do not like to see them. I am completely indifferent to their beauty and their geometric form. I like them for their statistical omnipresence, as most statisticians like the Gaussian.

I like to imagine sometimes that the Gaussian and related distributions are to systems whose variables are independent, as the fractal distributions - the Zipf-Mandelbrot distributions and the like - are to systems whose variables are dependent. This is not an evidenced thought.

Outside of fantasy, we can state a more specific fact about a more specific system whose variable are obviously dependent. I will claim that the global structure of the set of points created by word2vec in a high-dimensional vector space is a fractal, and buttress this claim with evidence. I will have one chart and _no pictures_.

It is exceedingly easy to intuitively define what a fractal is if you are allowed to use pictures and exceedingly hard if you are not allowed to use pictures. I will use a sufficient but not necessary definition: having a Minkowski-Bouligand dimension greater than the topological dimension.

That definition with Minkowski-Bouligand dimension is the empirical counterpart to Mandelbrot's obsolete definition of 1982, which talked about Hausdorff-Besicovich dimension instead of Minkowski-Bouligand dimension, and it is also obsolete. But it is obsolete __because__ it is sufficient but not necessary. That is, it has false negatives: it tends to identify objects as non-fractals which are actually fractals. So it is actually a higher bar than is necessary to prove that an object, in this case this set of points in n-dimensional space, is a fractal.





Upon inspection, you may note that this procedure is subject to the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality). To ameliorate it, I take a low-dimensionality word2vec: only 10 dimensions.

The corpus is the [Brown corpus](http://www.nltk.org/book/ch02.html#brown-corpus), from newspapers. The word2vec implementation is the [Python wrapper](https://github.com/danielfrg/word2vec) around the original implementation. The code for the analysis of the vectors is [here](https://github.com/howonlee/wordvec_network) (there is some more analysis involving networks, which I have not written up).




I won't give any explanations for the phenomenon. But I suspect that it is related to Zipf's law, but in a more circuitous way than the easy explanation.

I would hypothesize that this is not an extraordinarily particular phenomenon about neural representations, limited to word2vec. Fractal structures and power-law distributions seem to be surprisingly common in neural networks. Try training a backpropagation multilayer perceptron on MNIST and then [take the histograms](https://github.com/howonlee/mlp_gradient_histograms) of the absolute values of the weights - you will get a very heavy tail on that histogram. I am currently implementing the [Clauset Shalizi Newman 2007](http://arxiv.org/abs/0706.1062) steps to find if it's a proper power law.

In the year 2016, if someone is told to model a random landscape, an imaginary landscape generated by computer, they would be remiss if they did not think about fractals. If someone is told to succinctly model real landscapes in order to compress them, they would be remiss if they did not think a little about fractals. I believe that in modelling a different kind of imaginary landscape - the energy landscapes that gradient descent algorithms rattle about in - we should investigate whether it is also remiss in this case to think a little about fractals.
