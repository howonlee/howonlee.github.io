---
layout: page
title: Chaos and Big Data
---

I want to quote from Chaos: A Short Introduction. I feel that it has a lot to do with the current state of modern high-dimensionality algorithms, keeping in mind that one of the intellectual roots of the neural network (or at least the Boltzmann machine) was the Ising model, another physical system of very many degrees of freedom. But before that quote, a poet by a turbulence man:

>Big whorls have little whirls,
>which feed on their velocity.
>And little whirls have lesser whirls,
>and so on to viscosity.

And now the quote from Chaos: A Short Introduction:

>The traditional theory of turbulence in state space reflected Richardson’s poem: it was thought that more and more periodic modes would be excited and tracing the linear sum of all those oscillations would require a very high-dimensional state space. So most physicists were expecting the attractors of turbulence to be high-dimensional doughnuts, or mathematically speaking, tori.
>
>In the early 1970s, David Ruelle and Floris Takens were looking for alternatives to smooth high-dimensional tori and ran into lower-dimensional fractal attractors; they found the fractal attractors ‘strange’. Today, the word ‘strange’ is used to describe the geometry of the attractor, specifically the fact that it is a fractal, while the word ‘chaos’ is used to describe the dynamics of the system. It is a useful distinction. The precise origin of the phrase 
strange attractor’ has been lost, but the term has proven an inspiring and appropriate label for these objects of mathematical physics. Since Hamiltonian systems have no attractors at all, they have no strange attractors. Nevertheless, chaotic time series from Hamiltonian systems often develop intricate patterns with stark inhomogeneity and hints of self-similarity called strange accumulators which persist for as long as we run our computers.

>Their ultimate fate remains unknown.
